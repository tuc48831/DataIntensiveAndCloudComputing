#!/usr/bin/env python
import datetime
import sys
import json

current_articleID = None
current_json = None
word = None

# input comes from STDIN
for line in sys.stdin:
    # remove leading and trailing whitespace
    line = line.strip()

    # parse the input we got from mapper.py
    articleID, jsonValue = line.split('\t', 1)
    
    # convert count (currently a string) to int
    try:
        jsonObj = json.loads(jsonValue)
    except TypeError:
        # count was not a number, so silently
        # ignore/discard this line
        continue
    
    if not current_articleID:
        current_articleID = articleID
        current_json = jsonObj

    # this IF-switch only works because Hadoop sorts map output
    # by key (here: word) before it is passed to the reducer
    if current_articleID == articleID:
        #if the object already exists in the map
        existingTimestamp = current_json['scrapeTimestamp']
        existingTime = datetime.datetime.strptime(existingTimestamp, "%Y-%m-%d %H:%M:%S")
        newTimestamp = jsonObj['scrapeTimestamp']
        newTime = datetime.datetime.strptime(existingTimestamp, "%Y-%m-%d %H:%M:%S")
        if existingTime > newTime:
            #the already existing entry is newer, merge onto the old one with the schema
            outputMap[articleID] = merger.merge(outputMap[articleID], jsonObj)
        elif existingTime < newTime:
            #the new entry is newer, merge onto the new one with the schema
            outputMap[articleID] = merger.merge(jsonObj, outputMap[articleID])
            
        current_json = 
    else:
        if current_word:
            # write result to STDOUT
            print '%s\t%s' % (current_word, current_count)
        current_count = count
        current_word = word

# do not forget to output the last word if needed!
if current_word == word:
    print '%s\t%s' % (current_word, current_count)
